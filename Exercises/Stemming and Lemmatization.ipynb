{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40470df6",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5841838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several Stemming algorithms available. We will use PorterStemmer that comes with nltk library.\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "077f7135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "announc\n",
      "mice\n",
      "run\n",
      "wa\n",
      "unnecessari\n",
      "wari\n",
      "indic\n"
     ]
    }
   ],
   "source": [
    "# Create a stemming object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Pass a value to the stemmer\n",
    "\n",
    "print(stemmer.stem('walking')) # returns 'walk'\n",
    "print(stemmer.stem('Announcing')) # returns 'announc' which is not a real word. T\n",
    "                                  #this shows that Stemming is a crude approach\n",
    "print(stemmer.stem('Mice')) # although the 'mice' is plural, there is no 's' at the end. \n",
    "                            # the Stemmer returns the word as is. Therefore we choose Lemmatization for such words.\n",
    "print(stemmer.stem('running'))# Returns run\n",
    "print(stemmer.stem('was')) # returns 'wa' which is not a real word\n",
    "print(stemmer.stem('unnecessary')) # returned 'unnecessari', this happens based on whether the word ends with 'y'\n",
    "print(stemmer.stem('wary')) # returned 'wari'\n",
    "print(stemmer.stem('indices')) # retruned 'indic', again not a real word. It stemmed the 'es' part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d031a8ab",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebd015a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization algos appear in nltk, spaCy etc. here we use nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b37dce0",
   "metadata": {},
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4') #Recieved an error asking for this data. hence downloaded this using nltk Downloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fc7135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse\n"
     ]
    }
   ],
   "source": [
    "# create a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize('mice')) # Returns 'mouse' as it is the root word for 'mice'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7eb11063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going\n",
      "go\n",
      "walk\n",
      "good\n"
     ]
    }
   ],
   "source": [
    "# sometimes a word can be a noun, verb, adjective depending on Parts of Speech.\n",
    "# For example\n",
    "print(lemmatizer.lemmatize('going')) # Returns 'going' instead of 'go'.\n",
    "\n",
    "# We have to let the module know that 'going' is a verb and not a noun\n",
    "print(lemmatizer.lemmatize('going', pos = wordnet.VERB)) # Returns 'go', which is desired.\n",
    "print(lemmatizer.lemmatize('walking', pos = wordnet.VERB)) # Recognizes that 'walking' is verb.\n",
    "print(lemmatizer.lemmatize('better', pos = wordnet.ADJ)) # Returns 'good' as better is an adjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b163020",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Chaitra.b.c\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sometimes we need the pos tags inorder determine whether the word is a noun, adjective, conjunction or other parts\n",
    "# of speech. We can use nltk's pos_tags to do the job.\n",
    "# We have to donwload a pos tagger called 'averaged_perceptron_tagger'\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78efa5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Andrew', 'Tate', 'has', 'a', 'world-wide', 'following']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Andrew', 'NNP'),\n",
       " ('Tate', 'NNP'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('world-wide', 'JJ'),\n",
       " ('following', 'NN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets use a sentence which has a word which can be noun or verb depending on the position.\n",
    "sentence = 'Andrew Tate has a world-wide following'\n",
    "\n",
    "# split them into tokens\n",
    "tokens = sentence.split()\n",
    "print(tokens)\n",
    "\n",
    "# tag them using nltk's parts of speech tagger\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95934680",
   "metadata": {},
   "source": [
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all the kids'\n",
    "POS\tpossessive ending\tparent\\'s\n",
    "PRP\tpersonal pronoun\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7188caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the word using a if-elif ladder. We can use a predefined dictionary for this mapping.\n",
    "def get_wordnet_tags(token_tags):\n",
    "    if token_tags.startswith(('J','D')):\n",
    "        return wordnet.ADJ\n",
    "    elif token_tags.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif token_tags.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84c32f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence :  Andrew Tate has a world-wide following\n",
      "Lemmatized sentence :  Andrew Tate have a world-wide following\n"
     ]
    }
   ],
   "source": [
    "# Empty list to contain the root words\n",
    "root_word_list = []\n",
    "\n",
    "# We have to do the lemmatization one by one for each word.\n",
    "for tagged_token in tagged_tokens:\n",
    "    root_word = lemmatizer.lemmatize(tagged_token[0], pos = get_wordnet_tags(tagged_token[1]))\n",
    "    root_word_list.append(root_word)\n",
    "\n",
    "print('original sentence : ',sentence)\n",
    "print('Lemmatized sentence : ',' '.join(root_word_list))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "385c1694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADJ',\n",
       " 'ADJ_SAT',\n",
       " 'ADV',\n",
       " 'MORPHOLOGICAL_SUBSTITUTIONS',\n",
       " 'NOUN',\n",
       " 'VERB',\n",
       " '_ENCODING',\n",
       " '_FILEMAP',\n",
       " '_FILES',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_citation',\n",
       " '_compute_max_depth',\n",
       " '_data_file',\n",
       " '_data_file_map',\n",
       " '_encoding',\n",
       " '_exception_map',\n",
       " '_fileids',\n",
       " '_get_root',\n",
       " '_key_count_file',\n",
       " '_key_synset_file',\n",
       " '_lang_data',\n",
       " '_lemma_pos_offset_map',\n",
       " '_lexnames',\n",
       " '_license',\n",
       " '_load_exception_map',\n",
       " '_load_lang_data',\n",
       " '_load_lemma_pos_offset_map',\n",
       " '_max_depth',\n",
       " '_morphy',\n",
       " '_omw_reader',\n",
       " '_pos_names',\n",
       " '_pos_numbers',\n",
       " '_readme',\n",
       " '_root',\n",
       " '_synset_from_pos_and_line',\n",
       " '_synset_from_pos_and_offset',\n",
       " '_synset_offset_cache',\n",
       " '_tagset',\n",
       " '_unload',\n",
       " 'abspath',\n",
       " 'abspaths',\n",
       " 'all_eng_synsets',\n",
       " 'all_lemma_names',\n",
       " 'all_omw_synsets',\n",
       " 'all_synsets',\n",
       " 'citation',\n",
       " 'corpus2sk',\n",
       " 'custom_lemmas',\n",
       " 'digraph',\n",
       " 'doc',\n",
       " 'encoding',\n",
       " 'ensure_loaded',\n",
       " 'fileids',\n",
       " 'get_version',\n",
       " 'ic',\n",
       " 'jcn_similarity',\n",
       " 'langs',\n",
       " 'lch_similarity',\n",
       " 'lemma',\n",
       " 'lemma_count',\n",
       " 'lemma_from_key',\n",
       " 'lemmas',\n",
       " 'lg_attrs',\n",
       " 'license',\n",
       " 'lin_similarity',\n",
       " 'map30',\n",
       " 'map_wn30',\n",
       " 'morphy',\n",
       " 'of2ss',\n",
       " 'omw_prov',\n",
       " 'open',\n",
       " 'path_similarity',\n",
       " 'provenances',\n",
       " 'raw',\n",
       " 'readme',\n",
       " 'res_similarity',\n",
       " 'root',\n",
       " 'ss2of',\n",
       " 'synset',\n",
       " 'synset_from_pos_and_offset',\n",
       " 'synset_from_sense_key',\n",
       " 'synsets',\n",
       " 'words',\n",
       " 'wup_similarity']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wordnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
