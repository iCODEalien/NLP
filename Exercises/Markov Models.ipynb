{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df09c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce71e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of sentences\n",
    "\n",
    "list_of_sentences = ['I hate eggs',\n",
    "                    'I like Bacon and Jam',\n",
    "                    'Ben likes chicken sandwich']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6a7f708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ['i', 'bacon', 'hate', 'likes', 'eggs', 'chicken', 'ben', 'sandwich', 'jam', 'like', 'and']\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "Vocabulary = list(set([ word.lower() for sentence in list_of_sentences for word in sentence.split()]))\n",
    "print(len(Vocabulary), Vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0c5b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_of words\n",
    "def count_of_words(list_of_sentences):\n",
    "    # initializing a dict\n",
    "    count_dict = {}\n",
    "    \n",
    "    # finding the vocabulary\n",
    "    Vocabulary = list(set([ word.lower() for sentence in list_of_sentences for word in sentence.split()]))\n",
    "    #print(Vocabulary)\n",
    "    \n",
    "    for sentence in list_of_sentences:\n",
    "        #print(sentence)\n",
    "        for token in Vocabulary:\n",
    "            similar_words = [word.lower() for word in sentence.split() if word.lower() == token]\n",
    "            if count_dict.get(token):\n",
    "                count_dict[token] += len(similar_words)\n",
    "            else:\n",
    "                count_dict[token] = 0 if len(similar_words) == 0 else len(similar_words)\n",
    "    \n",
    "    return count_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63d0ba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 2,\n",
       " 'bacon': 1,\n",
       " 'hate': 1,\n",
       " 'likes': 1,\n",
       " 'eggs': 1,\n",
       " 'chicken': 1,\n",
       " 'ben': 1,\n",
       " 'sandwich': 1,\n",
       " 'jam': 1,\n",
       " 'like': 1,\n",
       " 'and': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_words(list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab63da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to find count for each time a sentence is started with a word from the vocabulary\n",
    "# store the count for that particular word\n",
    "\n",
    "def startswith_count(list_of_sentences, Vocabulary):\n",
    "    # setting up the dict\n",
    "    start_word_count = {key:0 for key in Vocabulary}\n",
    "    \n",
    "    for sentence in list_of_sentences:\n",
    "        for word in Vocabulary:\n",
    "            #print(word)\n",
    "            #print(start_word_count[word])\n",
    "            if sentence.startswith(word.capitalize()):\n",
    "                start_word_count[word] += 1\n",
    "    \n",
    "    return start_word_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17df6e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sandwich': 0,\n",
       " 'hate': 0,\n",
       " 'like': 0,\n",
       " 'ben': 1,\n",
       " 'and': 0,\n",
       " 'bacon': 0,\n",
       " 'i': 2,\n",
       " 'eggs': 0,\n",
       " 'jam': 0,\n",
       " 'likes': 0,\n",
       " 'chicken': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validating\n",
    "# this will be our Inital State Distribuion vector once we divide it by the total number of sentences.\n",
    "start_word_count = startswith_count(list_of_sentences, Vocabulary)\n",
    "start_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60eeaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to find the the combination of all the words in the Vocabulary\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51649910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sandwich', 'hate'),\n",
       " ('sandwich', 'like'),\n",
       " ('sandwich', 'ben'),\n",
       " ('sandwich', 'and'),\n",
       " ('sandwich', 'bacon'),\n",
       " ('sandwich', 'i'),\n",
       " ('sandwich', 'eggs'),\n",
       " ('sandwich', 'jam'),\n",
       " ('sandwich', 'likes'),\n",
       " ('sandwich', 'chicken'),\n",
       " ('hate', 'sandwich'),\n",
       " ('hate', 'like'),\n",
       " ('hate', 'ben'),\n",
       " ('hate', 'and'),\n",
       " ('hate', 'bacon'),\n",
       " ('hate', 'i'),\n",
       " ('hate', 'eggs'),\n",
       " ('hate', 'jam'),\n",
       " ('hate', 'likes'),\n",
       " ('hate', 'chicken'),\n",
       " ('like', 'sandwich'),\n",
       " ('like', 'hate'),\n",
       " ('like', 'ben'),\n",
       " ('like', 'and'),\n",
       " ('like', 'bacon'),\n",
       " ('like', 'i'),\n",
       " ('like', 'eggs'),\n",
       " ('like', 'jam'),\n",
       " ('like', 'likes'),\n",
       " ('like', 'chicken'),\n",
       " ('ben', 'sandwich'),\n",
       " ('ben', 'hate'),\n",
       " ('ben', 'like'),\n",
       " ('ben', 'and'),\n",
       " ('ben', 'bacon'),\n",
       " ('ben', 'i'),\n",
       " ('ben', 'eggs'),\n",
       " ('ben', 'jam'),\n",
       " ('ben', 'likes'),\n",
       " ('ben', 'chicken'),\n",
       " ('and', 'sandwich'),\n",
       " ('and', 'hate'),\n",
       " ('and', 'like'),\n",
       " ('and', 'ben'),\n",
       " ('and', 'bacon'),\n",
       " ('and', 'i'),\n",
       " ('and', 'eggs'),\n",
       " ('and', 'jam'),\n",
       " ('and', 'likes'),\n",
       " ('and', 'chicken'),\n",
       " ('bacon', 'sandwich'),\n",
       " ('bacon', 'hate'),\n",
       " ('bacon', 'like'),\n",
       " ('bacon', 'ben'),\n",
       " ('bacon', 'and'),\n",
       " ('bacon', 'i'),\n",
       " ('bacon', 'eggs'),\n",
       " ('bacon', 'jam'),\n",
       " ('bacon', 'likes'),\n",
       " ('bacon', 'chicken'),\n",
       " ('i', 'sandwich'),\n",
       " ('i', 'hate'),\n",
       " ('i', 'like'),\n",
       " ('i', 'ben'),\n",
       " ('i', 'and'),\n",
       " ('i', 'bacon'),\n",
       " ('i', 'eggs'),\n",
       " ('i', 'jam'),\n",
       " ('i', 'likes'),\n",
       " ('i', 'chicken'),\n",
       " ('eggs', 'sandwich'),\n",
       " ('eggs', 'hate'),\n",
       " ('eggs', 'like'),\n",
       " ('eggs', 'ben'),\n",
       " ('eggs', 'and'),\n",
       " ('eggs', 'bacon'),\n",
       " ('eggs', 'i'),\n",
       " ('eggs', 'jam'),\n",
       " ('eggs', 'likes'),\n",
       " ('eggs', 'chicken'),\n",
       " ('jam', 'sandwich'),\n",
       " ('jam', 'hate'),\n",
       " ('jam', 'like'),\n",
       " ('jam', 'ben'),\n",
       " ('jam', 'and'),\n",
       " ('jam', 'bacon'),\n",
       " ('jam', 'i'),\n",
       " ('jam', 'eggs'),\n",
       " ('jam', 'likes'),\n",
       " ('jam', 'chicken'),\n",
       " ('likes', 'sandwich'),\n",
       " ('likes', 'hate'),\n",
       " ('likes', 'like'),\n",
       " ('likes', 'ben'),\n",
       " ('likes', 'and'),\n",
       " ('likes', 'bacon'),\n",
       " ('likes', 'i'),\n",
       " ('likes', 'eggs'),\n",
       " ('likes', 'jam'),\n",
       " ('likes', 'chicken'),\n",
       " ('chicken', 'sandwich'),\n",
       " ('chicken', 'hate'),\n",
       " ('chicken', 'like'),\n",
       " ('chicken', 'ben'),\n",
       " ('chicken', 'and'),\n",
       " ('chicken', 'bacon'),\n",
       " ('chicken', 'i'),\n",
       " ('chicken', 'eggs'),\n",
       " ('chicken', 'jam'),\n",
       " ('chicken', 'likes')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(combinations(start_word_count.keys(),2))\n",
    "# its a good idea, but doesnot retain the order.\n",
    "combi_list = []\n",
    "\n",
    "for word1 in start_word_count.keys():\n",
    "    #print(word1)\n",
    "    for word2 in start_word_count.keys():\n",
    "        if word1 != word2:\n",
    "            combi_list.append((word1,word2))\n",
    "\n",
    "combi_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5adfabcf",
   "metadata": {},
   "source": [
    "# we will use this simple approach to find the count\n",
    "'Ben likes Chicken Sandwich '.lower().count('chicken sandwich')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4aaf39cd",
   "metadata": {},
   "source": [
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]], columns = ['I' ,'hate','eggs'], index = ['I' ,'hate','eggs'])\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f763c8b6",
   "metadata": {},
   "source": [
    "np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ef59825",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_matrix= np.zeros((Vocabulary.__len__(),Vocabulary.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c62122ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sandwich</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>ben</th>\n",
       "      <th>and</th>\n",
       "      <th>bacon</th>\n",
       "      <th>i</th>\n",
       "      <th>eggs</th>\n",
       "      <th>jam</th>\n",
       "      <th>likes</th>\n",
       "      <th>chicken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sandwich</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sandwich  hate  like  ben  and  bacon    i  eggs  jam  likes  \\\n",
       "sandwich       0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "hate           0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "like           0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "ben            0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "and            0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "bacon          0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "i              0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "eggs           0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "jam            0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "likes          0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "chicken        0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "          chicken  \n",
       "sandwich      0.0  \n",
       "hate          0.0  \n",
       "like          0.0  \n",
       "ben           0.0  \n",
       "and           0.0  \n",
       "bacon         0.0  \n",
       "i             0.0  \n",
       "eggs          0.0  \n",
       "jam           0.0  \n",
       "likes         0.0  \n",
       "chicken       0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A 10x10 Dataframe.\n",
    "df_zeros = pd.DataFrame(zero_matrix, columns = Vocabulary, index = Vocabulary)\n",
    "df_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef92462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'hate',\n",
       " 'eggs',\n",
       " 'i',\n",
       " 'like',\n",
       " 'bacon',\n",
       " 'and',\n",
       " 'jam',\n",
       " 'ben',\n",
       " 'likes',\n",
       " 'chicken',\n",
       " 'sandwich']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 =  [word.lower() for sentence in list_of_sentences for word in sentence.split()]\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db4d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate',\n",
       " 'eggs',\n",
       " 'i',\n",
       " 'like',\n",
       " 'bacon',\n",
       " 'and',\n",
       " 'jam',\n",
       " 'ben',\n",
       " 'likes',\n",
       " 'chicken',\n",
       " 'sandwich',\n",
       " 'i']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = [x.lower() for x in l1]\n",
    "l2.append(l2.pop(0))\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e62c1724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'hate',\n",
       " 'eggs',\n",
       " 'i',\n",
       " 'like',\n",
       " 'bacon',\n",
       " 'and',\n",
       " 'jam',\n",
       " 'ben',\n",
       " 'likes',\n",
       " 'chicken',\n",
       " 'sandwich']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b3145b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'hate'),\n",
       " ('hate', 'eggs'),\n",
       " ('eggs', 'i'),\n",
       " ('i', 'like'),\n",
       " ('like', 'bacon'),\n",
       " ('bacon', 'and'),\n",
       " ('and', 'jam'),\n",
       " ('jam', 'ben'),\n",
       " ('ben', 'likes'),\n",
       " ('likes', 'chicken'),\n",
       " ('chicken', 'sandwich')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = [*zip(l1,l2)]\n",
    "l3.pop()\n",
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ebea838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Combi :  ('hate', 'eggs')   pair :  ('hate', 'eggs')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('like', 'bacon')   pair :  ('like', 'bacon')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('ben', 'likes')   pair :  ('ben', 'likes')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('and', 'jam')   pair :  ('and', 'jam')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('bacon', 'and')   pair :  ('bacon', 'and')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('i', 'hate')   pair :  ('i', 'hate')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('i', 'like')   pair :  ('i', 'like')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('eggs', 'i')   pair :  ('eggs', 'i')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('jam', 'ben')   pair :  ('jam', 'ben')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('likes', 'chicken')   pair :  ('likes', 'chicken')    DF Value :  0.0\n",
      "**************************************************\n",
      "True Combi :  ('chicken', 'sandwich')   pair :  ('chicken', 'sandwich')    DF Value :  0.0\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# to update the corresponding values in the dataframe using the ngrams\n",
    "for combi in combi_list:\n",
    "    for pair in l3:\n",
    "        #print(pair)\n",
    "        if combi == pair:\n",
    "            print(True, 'Combi : ',combi,'  pair : ',pair, '   DF Value : ', df_zeros.loc[combi[0],combi[1]] )\n",
    "            print('*'*50)\n",
    "            df_zeros.loc[combi[0],combi[1]] += 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "784839a3",
   "metadata": {},
   "source": [
    "for combi in combi_list:\n",
    "    similar_words = []\n",
    "    similar_words = [pair for pair in l3 if combi == pair]\n",
    "    print(f'{combi} : ',len(similar_words))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e78cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeros.loc[combi[0],combi[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "672c702b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sandwich</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>ben</th>\n",
       "      <th>and</th>\n",
       "      <th>bacon</th>\n",
       "      <th>i</th>\n",
       "      <th>eggs</th>\n",
       "      <th>jam</th>\n",
       "      <th>likes</th>\n",
       "      <th>chicken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sandwich</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sandwich  hate  like  ben  and  bacon    i  eggs  jam  likes  \\\n",
       "sandwich       0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "hate           0.0   0.0   0.0  0.0  0.0    0.0  0.0   1.0  0.0    0.0   \n",
       "like           0.0   0.0   0.0  0.0  0.0    1.0  0.0   0.0  0.0    0.0   \n",
       "ben            0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    1.0   \n",
       "and            0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  1.0    0.0   \n",
       "bacon          0.0   0.0   0.0  0.0  1.0    0.0  0.0   0.0  0.0    0.0   \n",
       "i              0.0   1.0   1.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "eggs           0.0   0.0   0.0  0.0  0.0    0.0  1.0   0.0  0.0    0.0   \n",
       "jam            0.0   0.0   0.0  1.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "likes          0.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "chicken        1.0   0.0   0.0  0.0  0.0    0.0  0.0   0.0  0.0    0.0   \n",
       "\n",
       "          chicken  \n",
       "sandwich      0.0  \n",
       "hate          0.0  \n",
       "like          0.0  \n",
       "ben           0.0  \n",
       "and           0.0  \n",
       "bacon         0.0  \n",
       "i             0.0  \n",
       "eggs          0.0  \n",
       "jam           0.0  \n",
       "likes         1.0  \n",
       "chicken       0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69ee0a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sandwich</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>ben</th>\n",
       "      <th>and</th>\n",
       "      <th>bacon</th>\n",
       "      <th>i</th>\n",
       "      <th>eggs</th>\n",
       "      <th>jam</th>\n",
       "      <th>likes</th>\n",
       "      <th>chicken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sandwich</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jam</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sandwich  hate  like  ben  and  bacon    i  eggs  jam  likes  \\\n",
       "sandwich       1.0   1.0   1.0  1.0  1.0    1.0  1.0   1.0  1.0    1.0   \n",
       "hate           1.0   1.0   1.0  1.0  1.0    1.0  1.0   2.0  1.0    1.0   \n",
       "like           1.0   1.0   1.0  1.0  1.0    2.0  1.0   1.0  1.0    1.0   \n",
       "ben            1.0   1.0   1.0  1.0  1.0    1.0  1.0   1.0  1.0    2.0   \n",
       "and            1.0   1.0   1.0  1.0  1.0    1.0  1.0   1.0  2.0    1.0   \n",
       "bacon          1.0   1.0   1.0  1.0  2.0    1.0  1.0   1.0  1.0    1.0   \n",
       "i              1.0   2.0   2.0  1.0  1.0    1.0  1.0   1.0  1.0    1.0   \n",
       "eggs           1.0   1.0   1.0  1.0  1.0    1.0  2.0   1.0  1.0    1.0   \n",
       "jam            1.0   1.0   1.0  2.0  1.0    1.0  1.0   1.0  1.0    1.0   \n",
       "likes          1.0   1.0   1.0  1.0  1.0    1.0  1.0   1.0  1.0    1.0   \n",
       "chicken        2.0   1.0   1.0  1.0  1.0    1.0  1.0   1.0  1.0    1.0   \n",
       "\n",
       "          chicken  \n",
       "sandwich      1.0  \n",
       "hate          1.0  \n",
       "like          1.0  \n",
       "ben           1.0  \n",
       "and           1.0  \n",
       "bacon         1.0  \n",
       "i             1.0  \n",
       "eggs          1.0  \n",
       "jam           1.0  \n",
       "likes         2.0  \n",
       "chicken       1.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add-One Smoothing.\n",
    "df_zeros = df_zeros + 1\n",
    "df_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a58c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sandwich': 0,\n",
       " 'hate': 0,\n",
       " 'like': 0,\n",
       " 'ben': 1,\n",
       " 'and': 0,\n",
       " 'bacon': 0,\n",
       " 'i': 2,\n",
       " 'eggs': 0,\n",
       " 'jam': 0,\n",
       " 'likes': 0,\n",
       " 'chicken': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "179ccf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing by sum of startcount and length of vocabulary\n",
    "for k,v in start_word_count.items():\n",
    "    df_zeros.loc[k] = df_zeros.loc[k].div(start_word_count[k] + Vocabulary.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc604d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sandwich</th>\n",
       "      <th>hate</th>\n",
       "      <th>like</th>\n",
       "      <th>ben</th>\n",
       "      <th>and</th>\n",
       "      <th>bacon</th>\n",
       "      <th>i</th>\n",
       "      <th>eggs</th>\n",
       "      <th>jam</th>\n",
       "      <th>likes</th>\n",
       "      <th>chicken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sandwich</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hate</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ben</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bacon</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eggs</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jam</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chicken</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sandwich      hate      like       ben       and     bacon  \\\n",
       "sandwich  0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "hate      0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "like      0.090909  0.090909  0.090909  0.090909  0.090909  0.181818   \n",
       "ben       0.083333  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "and       0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "bacon     0.090909  0.090909  0.090909  0.090909  0.181818  0.090909   \n",
       "i         0.076923  0.153846  0.153846  0.076923  0.076923  0.076923   \n",
       "eggs      0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "jam       0.090909  0.090909  0.090909  0.181818  0.090909  0.090909   \n",
       "likes     0.090909  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "chicken   0.181818  0.090909  0.090909  0.090909  0.090909  0.090909   \n",
       "\n",
       "                 i      eggs       jam     likes   chicken  \n",
       "sandwich  0.090909  0.090909  0.090909  0.090909  0.090909  \n",
       "hate      0.090909  0.181818  0.090909  0.090909  0.090909  \n",
       "like      0.090909  0.090909  0.090909  0.090909  0.090909  \n",
       "ben       0.083333  0.083333  0.083333  0.166667  0.083333  \n",
       "and       0.090909  0.090909  0.181818  0.090909  0.090909  \n",
       "bacon     0.090909  0.090909  0.090909  0.090909  0.090909  \n",
       "i         0.076923  0.076923  0.076923  0.076923  0.076923  \n",
       "eggs      0.181818  0.090909  0.090909  0.090909  0.090909  \n",
       "jam       0.090909  0.090909  0.090909  0.090909  0.090909  \n",
       "likes     0.090909  0.090909  0.090909  0.090909  0.181818  \n",
       "chicken   0.090909  0.090909  0.090909  0.090909  0.090909  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Markov model for the given corpus.\n",
    "df_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f2b700",
   "metadata": {},
   "source": [
    "# Creating classes and functions for each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7125cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a function to remove punctuations\n",
    "def remove_punct(input_data):\n",
    "    # create a translation table\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    #print(type(input_data))\n",
    "    \n",
    "    try:\n",
    "        if type(input_data) == str:\n",
    "            \n",
    "            # get the clean string\n",
    "            clean_string = input_data.translate(translator)\n",
    "    \n",
    "            return clean_string\n",
    "        \n",
    "        elif type(input_data) == list:\n",
    "            # create a clean list\n",
    "            clean_list = []\n",
    "            \n",
    "            #loop thorugh each text in the list and then translate\n",
    "            for sentence in input_data:\n",
    "                # remove punctuations\n",
    "                clean_str = sentence.translate(translator)\n",
    "                \n",
    "                # append the cleaned sentence\n",
    "                clean_list.append(clean_str)\n",
    "            \n",
    "            return clean_list\n",
    "    \n",
    "    except ImportError:\n",
    "        print('String module not imported!, Try -> import string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b79304",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_texts = ['hello !',\n",
    "                'Nice to see you!',\n",
    "                'What? There is a discount?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2ce472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello ', 'Nice to see you', 'What There is a discount']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct(list_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5a1fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello my name is emiway'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punct('Hello! my name is emiway')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26b660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the Vocabulary\n",
    "def vocabulary_of(list_of_sent):\n",
    "    try:\n",
    "        Vocab = list(set([ word.lower() for sentence in list_of_sent for word in remove_punct(sentence).split()]))\n",
    "        return Vocab\n",
    "    \n",
    "    except TypeError as e:\n",
    "        print(f'{e} : Please check the format, Required Format is ['<string1>','<string2>','<string3>']')\n",
    "        \n",
    "    except AttributeError as a:\n",
    "        print(f'{a} : The Elements/Texts of the list have to be string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cdf9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eminem', 'hello', 'my', 'chuu', 'what', 'name', 'chiki', 'is']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l4 = ['Hello! my name is Eminem',\n",
    "     'What? my name is ',\n",
    "      'What? my name is ',\n",
    "     'chiki chiki chiki chuu']\n",
    "vocabulary_of(l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "447a6f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'split' : The Elements/Texts of the list have to be string.\n"
     ]
    }
   ],
   "source": [
    "l5 = [{'did','Hello'}]\n",
    "vocabulary_of(l5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0791954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_sentences : [['Hello', 'my', 'name', 'is', 'Eminem'], ['What', 'my', 'name', 'is'], ['What', 'my', 'name', 'is'], ['chiki', 'chiki', 'chiki', 'chuu']]\n",
      "vocabulary :  ['eminem', 'hello', 'my', 'chuu', 'what', 'name', 'chiki', 'is']\n"
     ]
    }
   ],
   "source": [
    "# sentences that are tokenized in a list\n",
    "tokenized_sentences = [sentence.split() for sentence in remove_punct(l4)]\n",
    "\n",
    "Vocab = vocabulary_of(l4)\n",
    "\n",
    "print('tokenized_sentences :',tokenized_sentences)\n",
    "print('vocabulary : ',Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3aebe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_of words\n",
    "def count_of_words(tokenized_sentences, Vocabulary):\n",
    "    count_dict = {}\n",
    "    for sentence in tokenized_sentences:\n",
    "        for token in Vocabulary:\n",
    "            #print('token : ',token)\n",
    "            similar_words = [word.lower() for word in sentence if word.lower() == token]\n",
    "            #print('Similar words : ',similar_words)\n",
    "            if count_dict.get(token):\n",
    "                count_dict[token] += len(similar_words)\n",
    "            else:\n",
    "                count_dict[token] = 0 if len(similar_words) == 0 else len(similar_words)\n",
    "    \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda8bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eminem': 1,\n",
       " 'hello': 1,\n",
       " 'my': 3,\n",
       " 'chuu': 1,\n",
       " 'what': 2,\n",
       " 'name': 3,\n",
       " 'chiki': 3,\n",
       " 'is': 3}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_of_words(tokenized_sentences, Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a280e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to find count for each time a sentence is started with a word from the vocabulary\n",
    "# store the count for that particular word\n",
    "\n",
    "def startswith_count(list_of_sentences, Vocabulary):\n",
    "    # setting up the dict\n",
    "    start_word_count = {key:0 for key in Vocabulary}\n",
    "    \n",
    "    for sentence in list_of_sentences:\n",
    "        for word in Vocabulary:\n",
    "            #print(word)\n",
    "            #print(start_word_count[word])\n",
    "            if sentence.startswith(word.capitalize()) or sentence.startswith(word):\n",
    "                start_word_count[word] += 1\n",
    "    \n",
    "    return start_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1696b3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello! my name is Eminem', 'What? my name is ', 'What? my name is ', 'chiki chiki chiki chuu']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eminem': 0,\n",
       " 'hello': 1,\n",
       " 'my': 0,\n",
       " 'chuu': 0,\n",
       " 'what': 2,\n",
       " 'name': 0,\n",
       " 'chiki': 1,\n",
       " 'is': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(l4)\n",
    "startswith_count(remove_punct(l4), Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b86cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the functions to get the combinations. \n",
    "txt = 'Hello I am Ironman'\n",
    "ls = [word.lower() for word in txt.split()]\n",
    "\n",
    "def combi(ls):\n",
    "    if isinstance(ls, str):\n",
    "        #print(type(ls))\n",
    "        clean_str = remove_punct(ls).lower()\n",
    "        clean_str_list = [word for word in clean_str.split()]\n",
    "        clean_str_tokens = []\n",
    "        \n",
    "        for i in range(len(clean_str_list)):\n",
    "            if i+1<len(clean_str_list):\n",
    "                #print((clean_str_tokens[i],clean_str_tokens[i+1]))\n",
    "                clean_str_tokens.append((clean_str_list[i],clean_str_list[i+1]))\n",
    "            else:\n",
    "                #print((clean_str_tokens[i],clean_str_tokens[0]))\n",
    "                clean_str_tokens.append(((clean_str_list[i],clean_str_list[0])))\n",
    "                \n",
    "        return clean_str_tokens\n",
    "    \n",
    "    elif isinstance(ls,list):\n",
    "        #print(type(ls))\n",
    "        #print(ls)\n",
    "        tokenized_sent = []\n",
    "        for sentence in ls:\n",
    "            clean_str = remove_punct(sentence).lower()\n",
    "            clean_str_tokens = [word for word in clean_str.split()]\n",
    "            #print(clean_str_tokens)\n",
    "            clean_token_sent = []\n",
    "        \n",
    "            for i in range(len(clean_str_tokens)):\n",
    "                if i+1<len(clean_str_tokens):\n",
    "                    #print((clean_str_tokens[i],clean_str_tokens[i+1]))\n",
    "                    clean_token_sent.append((clean_str_tokens[i],clean_str_tokens[i+1]))\n",
    "                else:\n",
    "                    #print((clean_str_tokens[i],clean_str_tokens[0]))\n",
    "                    clean_token_sent.append((clean_str_tokens[i],clean_str_tokens[0]))\n",
    "                    \n",
    "            tokenized_sent.append(clean_token_sent)\n",
    "        return tokenized_sent\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb85b607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', \"i'm\", 'dixit']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = 'hello I\\'m dixit'\n",
    "ls1 = [word.lower() for word in txt1.split()]\n",
    "ls1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8a1e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', 'hate'), ('hate', 'eggs'), ('eggs', 'i')],\n",
       " [('i', 'like'),\n",
       "  ('like', 'bacon'),\n",
       "  ('bacon', 'and'),\n",
       "  ('and', 'jam'),\n",
       "  ('jam', 'i')],\n",
       " [('ben', 'likes'),\n",
       "  ('likes', 'chicken'),\n",
       "  ('chicken', 'sandwich'),\n",
       "  ('sandwich', 'ben')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi(list_of_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49c63512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('i', 'hate'), ('hate', 'eggs'), ('eggs', 'i')],\n",
       " [('i', 'like'),\n",
       "  ('like', 'bacon'),\n",
       "  ('bacon', 'and'),\n",
       "  ('and', 'jam'),\n",
       "  ('jam', 'i')],\n",
       " [('ben', 'likes'),\n",
       "  ('likes', 'chicken'),\n",
       "  ('chicken', 'sandwich'),\n",
       "  ('sandwich', 'ben')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dictionary to store the mappings and their corresonding probability values.\n",
    "# first lets get the bigrams for each sentences in the corpus.\n",
    "\n",
    "list_of_sentences\n",
    "\n",
    "combi(list_of_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49c96e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'hate'),\n",
       " ('hate', 'eggs'),\n",
       " ('eggs', 'i'),\n",
       " ('i', 'like'),\n",
       " ('like', 'bacon'),\n",
       " ('bacon', 'and'),\n",
       " ('and', 'jam'),\n",
       " ('jam', 'i'),\n",
       " ('ben', 'likes'),\n",
       " ('likes', 'chicken'),\n",
       " ('chicken', 'sandwich'),\n",
       " ('sandwich', 'ben')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulary\n",
    "voca1 = vocabulary_of(list_of_sentences)\n",
    "\n",
    "# To store the count\n",
    "d2 = {word.lower(): {} for word in voca1}\n",
    "\n",
    "# corpus's bigrams\n",
    "list_of_tuples = [item  for l in combi(list_of_sentences) for item in l]\n",
    "list_of_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87399a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default dictionary d3\n",
    "d3 = {}\n",
    "\n",
    "# mapping code\n",
    "for tup in list_of_tuples:\n",
    "    if d3.get(tup[0]):\n",
    "        if d3[tup[0]].get(tup[1]):\n",
    "            #print(True)\n",
    "            d3[tup[0]][tup[1]] += 1\n",
    "            print(d3[tup[0]][tup[1]])\n",
    "        else:\n",
    "            d3[tup[0]][tup[1]] = 1\n",
    "    else:\n",
    "        d3[tup[0]] = {}\n",
    "        if d3[tup[0]].get(tup[1]):\n",
    "            #print(True)\n",
    "            d3[tup[0]][tup[1]] += 1\n",
    "            print(d3[tup[0]][tup[1]])\n",
    "        else:\n",
    "            d3[tup[0]][tup[1]] = 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db060ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': {'hate': 1, 'like': 1},\n",
       " 'hate': {'eggs': 1},\n",
       " 'eggs': {'i': 1},\n",
       " 'like': {'bacon': 1},\n",
       " 'bacon': {'and': 1},\n",
       " 'and': {'jam': 1},\n",
       " 'jam': {'i': 1},\n",
       " 'ben': {'likes': 1},\n",
       " 'likes': {'chicken': 1},\n",
       " 'chicken': {'sandwich': 1},\n",
       " 'sandwich': {'ben': 1}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transition matrix in terms of mapping.\n",
    "d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15dbe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to create mappings\n",
    "\n",
    "def trans_mat_mapping(tuples_list, dict_data = {}):\n",
    "    for tup in tuples_list:\n",
    "        if dict_data.get(tup[0]):\n",
    "            if dict_data[tup[0]].get(tup[1]):\n",
    "                #print(True)\n",
    "                dict_data[tup[0]][tup[1]] += 1\n",
    "                print(dict_data[tup[0]][tup[1]])\n",
    "            else:\n",
    "                dict_data[tup[0]][tup[1]] = 1\n",
    "        else:\n",
    "            dict_data[tup[0]] = {}\n",
    "            if dict_data[tup[0]].get(tup[1]):\n",
    "                #print(True)\n",
    "                dict_data[tup[0]][tup[1]] += 1\n",
    "                print(dict_data[tup[0]][tup[1]])\n",
    "            else:\n",
    "                dict_data[tup[0]][tup[1]] = 1\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce66550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': {'Santa': 1}, 'Good': {'returns': 1}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_mat_mapping([('hi', 'Santa'),('Good', 'returns')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60df4be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_mat_mapping2(tuples_list):\n",
    "    dict_data = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for tup in tuples_list:\n",
    "        dict_data[tup[0]][tup[1]] += 1\n",
    "    \n",
    "    return dict(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb3f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi': defaultdict(int, {'Santa': 1}),\n",
       " 'Good': defaultdict(int, {'returns': 1})}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_mat_mapping2([('hi', 'Santa'),('Good', 'returns')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbc70625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': defaultdict(int, {'hate': 1, 'like': 1}),\n",
       " 'hate': defaultdict(int, {'eggs': 1}),\n",
       " 'eggs': defaultdict(int, {'i': 1}),\n",
       " 'like': defaultdict(int, {'bacon': 1}),\n",
       " 'bacon': defaultdict(int, {'and': 1}),\n",
       " 'and': defaultdict(int, {'jam': 1}),\n",
       " 'jam': defaultdict(int, {'i': 1}),\n",
       " 'ben': defaultdict(int, {'likes': 1}),\n",
       " 'likes': defaultdict(int, {'chicken': 1}),\n",
       " 'chicken': defaultdict(int, {'sandwich': 1}),\n",
       " 'sandwich': defaultdict(int, {'ben': 1})}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_mat_mapping2(list_of_tuples)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "718ccc58",
   "metadata": {},
   "source": [
    "# runtime\n",
    "start_time = time.time()\n",
    "\n",
    "trans_mat_mapping(list_of_tuples)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(end_time - start_time) # less data hence 0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88384ff2",
   "metadata": {},
   "source": [
    "# Memory allocation\n",
    "tracemalloc.start()\n",
    "\n",
    "trans_mat_mapping(list_of_tuples)\n",
    "\n",
    "current, peak = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37a8986d",
   "metadata": {},
   "source": [
    "# Current and Peak memory usage\n",
    "print(current, peak)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "800ebbde",
   "metadata": {},
   "source": [
    "# For the 2nd version\n",
    "tracemalloc.start()\n",
    "\n",
    "trans_mat_mapping2(list_of_tuples)\n",
    "\n",
    "current2, peak2 = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42962848",
   "metadata": {},
   "source": [
    "print(current2, peak2) # second version is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac8a0343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate eggs', 'I like Bacon and Jam', 'Ben likes chicken sandwich']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corpus\n",
    "list_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e77ee348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'bacon',\n",
       " 'hate',\n",
       " 'likes',\n",
       " 'eggs',\n",
       " 'chicken',\n",
       " 'ben',\n",
       " 'sandwich',\n",
       " 'jam',\n",
       " 'like',\n",
       " 'and']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_1 = vocabulary_of(list_of_sentences)\n",
    "vocab_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51c7fc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 2,\n",
       " 'bacon': 0,\n",
       " 'hate': 0,\n",
       " 'likes': 0,\n",
       " 'eggs': 0,\n",
       " 'chicken': 0,\n",
       " 'ben': 1,\n",
       " 'sandwich': 0,\n",
       " 'jam': 0,\n",
       " 'like': 0,\n",
       " 'and': 0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count for each word based on whether it the sentences start with it.\n",
    "start_with_count = startswith_count(list_of_sentences, vocabulary_of(list_of_sentences))\n",
    "start_with_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b56b6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test text\n",
    "#test_txt = ['I hate eggs']\n",
    "test_txt = 'I hate eggs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3ce61dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'hate'), ('hate', 'eggs'), ('eggs', 'i')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the tuples/transitions/bigrams\n",
    "l1 = combi(test_txt)\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "677d9439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': {'hate': 1, 'like': 1},\n",
       " 'hate': {'eggs': 1},\n",
       " 'eggs': {'i': 1},\n",
       " 'like': {'bacon': 1},\n",
       " 'bacon': {'and': 1},\n",
       " 'and': {'jam': 1},\n",
       " 'jam': {'i': 1},\n",
       " 'ben': {'likes': 1},\n",
       " 'likes': {'chicken': 1},\n",
       " 'chicken': {'sandwich': 1},\n",
       " 'sandwich': {'ben': 1}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the state transition matrix\n",
    "st_trans_mat = trans_mat_mapping(list_of_tuples, {})\n",
    "st_trans_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6ed967a9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'i': 2,\n",
       " 'bacon': 1,\n",
       " 'hate': 1,\n",
       " 'likes': 1,\n",
       " 'eggs': 1,\n",
       " 'chicken': 1,\n",
       " 'ben': 1,\n",
       " 'sandwich': 1,\n",
       " 'jam': 1,\n",
       " 'like': 1,\n",
       " 'and': 1}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cOunt of each words in the corpus\n",
    "count_words = count_of_words(list_of_sentences)\n",
    "count_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3aebc422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want the conditional probabilities for each mutliplied and returned\n",
    "\n",
    "def cond_x_g_cls(list_of_bigrams, st_trans_mat):\n",
    "    product = 1\n",
    "    \n",
    "    for tup in list_of_bigrams:\n",
    "        if st_trans_mat.get(tup[0]) and st_trans_mat[tup[0]].get(tup[1]):\n",
    "            count = st_trans_mat[tup[0]][tup[1]]\n",
    "            print(f\"{tup[0]} --> {tup[1]} : \",count)\n",
    "            print('count : ',count,'Start_with_count : ',count_words[tup[0]] ,'Vocabulary : ', len(vocab_1))\n",
    "            product *= (count)/(count_words[tup[0]])\n",
    "        else:\n",
    "            product *= 1/len(vocab_1)\n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93e35e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i --> hate :  1\n",
      "count :  1 Start_with_count :  2 Vocabulary :  11\n",
      "hate --> eggs :  1\n",
      "count :  1 Start_with_count :  1 Vocabulary :  11\n",
      "eggs --> i :  1\n",
      "count :  1 Start_with_count :  1 Vocabulary :  11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_x_g_cls(l1, st_trans_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
